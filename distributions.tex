\documentclass{article}

\title{Probability Distributions}
\author{Rolf D. Svegstrup}

\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}
\maketitle

\section{Bernoulli Distribution}
A \emph{Bernoulli random variable}, $X$, takes the value 1 with probability $p$ and 0 otherwise. Thus,
\begin{equation}
\label{Eq: Bernoulli properties}
\begin{split}
E(X) &= p \\ 
V(X) &= p(1-p).
\end{split}
\end{equation}

\section{Binomial Distribution}
A \emph{Binomial random variable}, $X$, is a sum of $n$ iid. Bernoulli random variables. We write $X \sim B(n, p)$. Trivially,
\begin{equation}
P(X = k) = {n \choose k} p^k (1-p)^{n-k}.
\end{equation}
From (\ref{Eq: Bernoulli properties}) it follows that
\begin{equation}
\begin{split}
E(X) &= np \\
V(X) &= np(1-p) .
\end{split}
\end{equation}

\section{Poisson Distribution}
A \emph{Poisson random variable}, $X$, is given by ... LOTS OF EXPLANATION HERE.
\begin{equation}
P(X = k) = e^{-\lambda} \frac{\lambda^k}{k!}, \quad k \in \mathbb{N}_0
\end{equation}

\begin{equation}
\label{Eq: Poisson properties}
\begin{split}
E(X) &= \lambda \\
V(X) &= \lambda
\end{split}
\end{equation}

To prove (\ref{Eq: Poisson properties}) note that
\begin{equation*}
E(X) = e^{-\lambda} \sum_{k=0}^\infty k \frac{\lambda^k}{k!} = e^{-\lambda} \lambda \sum_{k=1}^\infty \frac{\lambda^{k-1}}{(k-1)!} = \lambda.
\end{equation*}
Similarly,
\begin{equation*}
E(X^2) = e^{-\lambda} \sum_{k=0}^\infty k^2 \frac{\lambda^k}{k!} = e^{-\lambda} \lambda \sum_{k=1}^\infty ((k-1) + 1) \frac{\lambda^{k-1}}{(k-1)!}
 = \lambda^2 + \lambda.
 \end{equation*}
 
 
 \section{Exponential Distribution}
 The exponential distribution describes waiting times without memory, e.g., radioactive decay or corporate default (with constant default rate).
 
 A random variable is exponentially distributed, $X \sim \textrm{Exp}(\lambda)$, if its density function is
 \begin{equation*}
 f(x;\lambda) = \lambda e^{-\lambda x}, \quad x \geq 0.
 \end{equation*}
 Equivalently, $P(X \geq h) = e^{-\lambda h}$. We note that
 \begin{equation}
 \begin{split}
 E(X) &= \frac{1}{\lambda} \\
 V(X) &= \frac{1}{\lambda^2}
 \end{split}
 \end{equation} 
 
 \subsection{Memoryless}
 For $t, \Delta t \geq 0$, 
 \begin{equation*}
 P(X \geq t + \Delta t \mid X \geq t) = \frac{e^{-\lambda (t + \Delta t)}}{e^{-\lambda t}} = P(X \geq \Delta t).
 \end{equation*}
Equivalently, the exponential hazard function is constant:
 \begin{equation*}
 h(t) dt = P(t < X < t + dt \mid X > t) = \frac{e^{-\lambda t} - e^{-\lambda (t+dt)}}{e^{-\lambda t}}  = \lambda dt .
 \end{equation*}
 
 	
 
 

\end{document}