\documentclass{article}

\title{Probability Distributions}
\author{Rolf D. Svegstrup}

\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}
\maketitle

\section{Bernoulli Distribution}
A \emph{Bernoulli random variable}, $X$, takes the value 1 with probability $p$ and 0 otherwise. Thus,
\begin{equation}
\label{Eq: Bernoulli properties}
\begin{split}
E(X) &= p \\ 
V(X) &= p(1-p).
\end{split}
\end{equation}

\section{Binomial Distribution}
A \emph{Binomial random variable}, $X$, is a sum of $n$ iid. Bernoulli random variables. We write $X \sim B(n, p)$. Trivially,
\begin{equation}
P(X = k) = {n \choose k} p^k (1-p)^{n-k}.
\end{equation}
From (\ref{Eq: Bernoulli properties}) it follows that
\begin{equation}
\begin{split}
E(X) &= np \\
V(X) &= np(1-p) .
\end{split}
\end{equation}

\section{Poisson Distribution}
A Poisson distribution describes the number of events of a Poisson process in a given timeframe. That is, it describes the number of events in a time interval when each infinitesimal time interval has the same chance of spawning an event. Equivalently it can be described as the number of completions of queued, independent processes where each process waits for the process ahead to finish and again, each infinitesimal time interval has the same chance of completing the process. In the limit it also describes the number of successes for a large number of iid. low-probability Bernoulli variables.

A \emph{Poisson random variable}, $X$, is given by 
\begin{equation}
P(X = k) = e^{-\lambda} \frac{\lambda^k}{k!}, \quad k \in \mathbb{N}_0
\end{equation}

\begin{equation}
\label{Eq: Poisson properties}
\begin{split}
E(X) &= \lambda \\
V(X) &= \lambda
\end{split}
\end{equation}

To prove (\ref{Eq: Poisson properties}) note that
\begin{equation*}
E(X) = e^{-\lambda} \sum_{k=0}^\infty k \frac{\lambda^k}{k!} = e^{-\lambda} \lambda \sum_{k=1}^\infty \frac{\lambda^{k-1}}{(k-1)!} = \lambda.
\end{equation*}
Similarly,
\begin{equation*}
E(X^2) = e^{-\lambda} \sum_{k=0}^\infty k^2 \frac{\lambda^k}{k!} = e^{-\lambda} \lambda \sum_{k=1}^\infty ((k-1) + 1) \frac{\lambda^{k-1}}{(k-1)!}
 = \lambda^2 + \lambda.
 \end{equation*}
 
 \subsection{Poisson Distribution from Binomial Distribution  in the Limit}
The Poisson distribution arises in the limit of Binomial distributions with the expected number of successes, $\lambda = pn$, kept fixed. 
\begin{equation*}
\begin{split}
P(X_n = k) &= {n \choose k} \left(\frac{\lambda}{n}\right)^k \left(1 - \frac{\lambda}{n}\right)^{n-k} \\
&= \frac{n!}{(n-k)! \, n^k} \frac{\lambda^k}{k!} \left(1 - \frac{\lambda}{n}\right)^{n-k} \\
& \xrightarrow {n \rightarrow \infty} \frac{\lambda}{k!} e^{-\lambda}.
\end{split}
\end{equation*}
This uses the limit, $\textrm{lim}(1-\frac{x}{n})^n = e^x$ (apply logarithm, use l'Hospital).

 
 \section{Exponential Distribution}
 The exponential distribution describes waiting times without memory, e.g., radioactive decay or corporate default (with constant default rate).
 
 A random variable is exponentially distributed, $X \sim \textrm{Exp}(\lambda)$, if its density function is
 \begin{equation*}
 f(x;\lambda) = \lambda e^{-\lambda x}, \quad x \geq 0.
 \end{equation*}
 Equivalently, $P(X \geq h) = e^{-\lambda h}$. We note that
 \begin{equation}
 \begin{split}
 E(X) &= \frac{1}{\lambda} \\
 V(X) &= \frac{1}{\lambda^2}
 \end{split}
 \end{equation} 
 
 \subsection{Memoryless}
 For $t, \Delta t \geq 0$, 
 \begin{equation*}
 P(X \geq t + \Delta t \mid X \geq t) = \frac{e^{-\lambda (t + \Delta t)}}{e^{-\lambda t}} = P(X \geq \Delta t).
 \end{equation*}
Equivalently, the exponential hazard function is constant:
 \begin{equation*}
 h(t) dt = P(t < X < t + dt \mid X > t) = \frac{e^{-\lambda t} - e^{-\lambda (t+dt)}}{e^{-\lambda t}}  = \lambda dt .
 \end{equation*}
 
 	
 
 

\end{document}